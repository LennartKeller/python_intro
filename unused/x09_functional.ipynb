{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einführung in das Programmieren mit Python\n",
    "# Comprehensions, Iteratoren und Generatoren: Funktionales Programmieren in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe\n",
    "\n",
    "Schreiben Sie einen einfachen Tokenizer: Der Tokenizer soll eine Textdatei zeilenweise einlesen und jede Zeile in Tokens (Wörter und Zahlen) zerlegen. Ihr Tokenizer soll als Funktion aufrufbar sein und eine lange Sequenz / Liste mit allen Tokens aus der Datei zurückgeben. Alle Tokens sollen in Kleinbuchstaben normalisiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kurzer', 'roman', 'dies', 'ist', 'ein', 'langer', 'roman', 'er', 'beginnt', 'mit', 'dem', 'auftritt', 'des', 'heldens', 'da', 'es', 'keine', 'helden', 'gibt', 'unterbricht', 'hier', 'schon', 'der', 'leser']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def tokenize(filename):\n",
    "    tokens = []\n",
    "    \n",
    "    with open(filename, \"rt\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            for token in re.findall(\"\\w+\", line):\n",
    "                tokens.append(token.lower())\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "print(tokenize(\"roman.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Comprehensions\n",
    "\n",
    "* Kurzschreibweise für systematisch aufgebaute Listen\n",
    "* z.B. Quadratzahlen: $Q := \\{ n^2 \\mid n \\in \\mathbb{N} \\}$\n",
    "* in Python: `[` _Ausdruck_ `for` _name_ `in` _sequenz_ … `]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 144, 169, 196, 225, 256, 289, 324, 361] <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "quadratzahlen = [ n**2 for n in range(20) ]\n",
    "print(quadratzahlen, type(quadratzahlen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Man kann auch __filtern__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 16, 36, 64, 100, 144, 196, 256, 324]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[n**2 for n in range(20) if n % 2 == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auf mehreren Zeilen ist's u.U. übersichtlicher:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 16, 36, 64, 100, 144, 196, 256, 324]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ n**2 \n",
    "     for n in range(20) \n",
    "     if n % 2 == 0 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green;\">Aufgabe</h3>\n",
    "Schreiben Sie eine List Comprehension, die aus einem String eine in Liste der in Kleinbuchstaben gewandelten Tokens generiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dies', 'ist', 'ein', 'beispiel', 'für', 'eine', 'list', 'comprehension']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ token.lower() for token in re.findall(r\"\\w+\", \"Dies ist ein Beispiel für eine List Comprehension.\") ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"roman.txt\", encoding=\"utf-8\") as file:\n",
    "    result = [ re.findall(r'\\w+', line) for line in file ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Kurzer', 'Roman'], ['Dies', 'ist', 'ein', 'langer', 'Roman', 'Er', 'beginnt', 'mit', 'dem', 'Auftritt', 'des', 'Heldens'], ['Da', 'es', 'keine', 'Helden', 'gibt', 'unterbricht', 'hier', 'schon', 'der', 'Leser']]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kurzer', 'roman', 'dies', 'ist', 'ein', 'langer', 'roman', 'er', 'beginnt', 'mit', 'dem', 'auftritt', 'des', 'heldens', 'da', 'es', 'keine', 'helden', 'gibt', 'unterbricht', 'hier', 'schon', 'der', 'leser']\n"
     ]
    }
   ],
   "source": [
    "def tokenize(filename):\n",
    "    with open(filename, encoding=\"utf-8\") as file:\n",
    "        return [ token.lower()\n",
    "                      for line in file\n",
    "                      for token in re.findall(r\"\\w+\", line) ]\n",
    "print(tokenize(\"roman.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary Comprehensions\n",
    "\n",
    "Man kann auch Dictionaries auf diese Weise bauen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dies': 4, 'da': 2, 'helden': 6, 'keine': 5, 'dem': 3, 'schon': 5, 'es': 2, 'er': 2, 'langer': 6, 'heldens': 7, 'der': 3, 'gibt': 4, 'beginnt': 7, 'mit': 3, 'hier': 4, 'roman': 5, 'ein': 3, 'leser': 5, 'auftritt': 8, 'unterbricht': 11, 'des': 3, 'ist': 3, 'kurzer': 6}\n"
     ]
    }
   ],
   "source": [
    "print({ token : len(token)  for token in tokens })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
